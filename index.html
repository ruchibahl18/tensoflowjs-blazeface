<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Display Webcam Stream</title>

<style>
#videoElement {
	width: 500px;
	height: 375px;
	background-color: #666;
	display: none;
}
</style>
</head>
 
<body>
	<video autoplay="true" id="videoElement"></video>
	<canvas id='canvas' width = '600px' height='400px'></canvas>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
<script>
	let video = document.querySelector("#videoElement");
	let model;
	let canvas = document.querySelector("#canvas");
	let ctx = canvas.getContext('2d');
	const setupCamera = () => {
		if (navigator.mediaDevices.getUserMedia) {
		  navigator.mediaDevices.getUserMedia({ video: true })
			.then(function (stream) {
			  video.srcObject = stream;
			})
			.catch(function (err0r) {
			  console.log("Something went wrong!");
			});
		}
	}
	const detectFaces = async () => {
		const prediction = await model.estimateFaces(video,false);
		console.log(prediction);
		ctx.drawImage(video,0,0,600,400);
		prediction.forEach((pred) => {
			ctx.beginPath();
			ctx.lineWidth = "4";
			ctx.strokeStyle = "blue";
			ctx.rect(
				pred.topLeft[0],
				pred.topLeft[1],
				pred.bottomRight[0] - pred.topLeft[0],
				pred.bottomRight[1] - pred.topLeft[1]
			);
			ctx.stroke();
			ctx.fillStyle = "red";
			pred.landmarks.forEach((landmark) => {
				ctx.fillRect(landmark[0],landmark[1],5,5);
			});
		});
	};
	setupCamera();
	video.addEventListener("loadeddata", async () => {
		model = await blazeface.load();
		setInterval(detectFaces,100);
	});
</script>
</body>
</html>